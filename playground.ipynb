{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Text generation in the style of The Metamorphosis** #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import necessary dependencies** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load and preprocess the data** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffthe project gutenberg ebook of metamorphosis, by franz kafka\\ntranslated by david wyllie.\\n\\nthis ebook is for the use of anyone anywhere at no cost and with\\nalmost no restrictions whatsoever.  you may copy it, give it away or\\nre-use it under the terms of the project gutenberg license included\\nwith this ebook or online at www.gutenberg.net\\n\\n** this is a copyrighted project gutenberg ebook, details below **\\n**     please follow the copyright guidelines in this file.     **\\n\\n\\ntitle: metamorphosis\\n\\nauthor: franz kafka\\n\\ntranslator: david wyllie\\n\\nrelease date: august 16, 2005 [ebook #5200]\\nfirst posted: may 13, 2002\\nlast updated: may 20, 2012\\n\\nlanguage: english\\n\\n\\n*** start of this project gutenberg ebook metamorphosis ***\\n\\n\\n\\n\\ncopyright (c) 2002 david wyllie.\\n\\n\\n\\n\\n\\n  metamorphosis\\n  franz kafka\\n\\ntranslated by david wyllie\\n\\n\\n\\ni\\n\\n\\none morning, when gregor samsa woke from troubled dreams, he found\\nhimself transformed in his bed into a horrible vermin.  he lay on\\nhis armour-like back, and if he lif'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the text file and convert them all into lower case\n",
    "filename = \"data/kafka.txt\"\n",
    "raw_text = open(filename, encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()\n",
    "\n",
    "# print out the first 1000 characters\n",
    "raw_text[: 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '#', '$', '%', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\ufeff']\n"
     ]
    }
   ],
   "source": [
    "# get the list of all unique characters\n",
    "chars = sorted(list(set(raw_text)))\n",
    "\n",
    "# map between characters and their index, in both directions\n",
    "# so we can encode and decode between them\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# print out all unique characters\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  139056\n",
      "Total Vocab:  58\n"
     ]
    }
   ],
   "source": [
    "# number of raw characters and\n",
    "# number of unique characters in the text\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print (\"Total Characters: \", n_chars)\n",
    "print (\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  69478\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "skip = 2\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, skip):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print (\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features] to \n",
    "# feed into LSTM network\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize the data\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model training** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[\n",
    "          2]), return_sequences=True, implementation=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(256, implementation=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# save the model after each epoch if there is an improvement\n",
    "# (the loss reduced) for easily retrain and reload\n",
    "filepath = \"model_checkpoints/weights-improvement-{epoch:02d}-{loss:.4f}-bigger-continuing.hdf5\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath, monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# fit the model to the data\n",
    "# model.fit(X, y, epochs=24, batch_size=64, callbacks=callbacks_list, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Using LSTM network to generate text** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the network weights from the best epoch\n",
    "filename = \"model_checkpoints/weights-improvement-18-1.4017-bigger-continuing.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The context:\n",
      "\" elf and slammed the door shut\n",
      "again from outside.  but she seemed to regret her behaviour, as she\n",
      "op \"\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "Generated text: \n",
      " \"\n",
      "oeec the rall whrh the saie was she was and say the door of his poom and then he had been giaic oo his room.  the foorr would had eeen aala to fet the foor of the lookhe, but whnh his sister wasted to be help fomm.  he had never tple tha rhiet of his look on his back in the eoor of the booree and the suairs what whey was and santnd the tay the doorr wiat was not oo the counle oo cetee that he cada to coone the door and whth him monk on his room, ald he would have been aalk to miv his hin hn his \n",
      "\" \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# pick a random pattern \n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "\n",
    "# print out the pattern in human-readable form\n",
    "print (\"The context:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "print(\"-------------------------------------------------------------------\")\n",
    "print(\"\\nGenerated text: \\n\", \"\\\"\")\n",
    "\n",
    "\n",
    "# AI writer in action!\n",
    "for i in range(500):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print (\"\\n\\\"\", \"\\nDone.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
